{"cells":[{"cell_type":"markdown","metadata":{"id":"E-YPYQEfu6sB"},"source":["# Deep Learning workflow\n","1. Load the data\n","2. Process the data\n","3. Build a neural network model\n","4. Define a loss function\n","5. Define the Optimozer\n","6. Train the model\n","7. Evaluate the model\n","8. Save the model for future use\n","\n","\n","\n","\n"]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"d74ciW78q4Qn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zaWHn5NcutFv"},"outputs":[],"source":["import torch\n","from torch import nn                                 # Neural Network\n","from torch.utils.data import DataLoader              # DataLoader\n","from torchvision import datasets                     # torchvision library for specially for the computer vision task\n","from torchvision.transforms import ToTensor          # Convert image pixel values [0, 255] from the integer ranges [0.0, 1.0]."]},{"cell_type":"markdown","metadata":{"id":"8ColHiYWvelB"},"source":["PyTorch offers domain-specific libraries such as TorchText, TorchVision, and TorchAudio, all of which include datasets.\n","\n","The torchvision.datasets module contains Dataset objects for many real-world vision data like FashionMNIST, CIFAR, COCO.\n","\n","In this tutorial, we use the FashionMNIST dataset. Every TorchVision Dataset includes two arguments: transform and target_transform to modify the samples and labels respectively."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5088,"status":"ok","timestamp":1770020517887,"user":{"displayName":"Hemant Pandey (G25AIT1065)","userId":"04373902719597689004"},"user_tz":-330},"id":"qgCapoJ-veF2","outputId":"d5b04067-6d55-4ae0-806e-b9f2e7a3402b"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 26.4M/26.4M [00:01<00:00, 16.8MB/s]\n","100%|██████████| 29.5k/29.5k [00:00<00:00, 306kB/s]\n","100%|██████████| 4.42M/4.42M [00:00<00:00, 5.04MB/s]\n","100%|██████████| 5.15k/5.15k [00:00<00:00, 19.6MB/s]\n"]}],"source":["# Download training data from open datasets.\n","\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","# Download test data from open datasets.\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor(),\n",")"]},{"cell_type":"markdown","metadata":{"id":"_mDbGeJIvdms"},"source":["We pass the Dataset as an argument to DataLoader.\n","\n","This wraps an iterable over our dataset, and supports automatic batching, sampling, shuffling and multiprocess data loading.\n","\n","Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73,"status":"ok","timestamp":1770020517984,"user":{"displayName":"Hemant Pandey (G25AIT1065)","userId":"04373902719597689004"},"user_tz":-330},"id":"8GT6-bDQySsu","outputId":"06ee47ff-f37b-4782-ea59-6768ab7bcee0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n","Shape of y: torch.Size([64]) torch.int64\n"]}],"source":["batch_size = 64        # model take a 64 sample at a time\n","\n","# Create data loaders.\n","train_dataloader = DataLoader(training_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","for X, y in test_dataloader:\n","    print(f\"Shape of X [N, C, H, W]: {X.shape}\")      # where N: Batch size, C = 1 : Grayscale (Black & White), H: Image Height, W: image Weights\n","    print(f\"Shape of y: {y.shape} {y.dtype}\")\n","    break"]},{"cell_type":"markdown","metadata":{"id":"gAUnt2pmzE10"},"source":["# Creating Models\n","To define a neural network in PyTorch, we create a class that inherits from nn.Module.\n","\n","We define the layers of the network in the __init__ function and specify how data will pass through the network in the forward function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1770020518013,"user":{"displayName":"Hemant Pandey (G25AIT1065)","userId":"04373902719597689004"},"user_tz":-330},"id":"qajZueEjyh7F","outputId":"1f81b78f-694d-43a2-8f2a-9789f20b23c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (fc1): Linear(in_features=784, out_features=512, bias=True)\n","  (r1): ReLU()\n","  (fc2): Linear(in_features=512, out_features=512, bias=True)\n","  (r2): ReLU()\n","  (fc3): Linear(in_features=512, out_features=512, bias=True)\n","  (r3): ReLU()\n","  (fc4): Linear(in_features=512, out_features=10, bias=True)\n",")\n"]}],"source":["# Initialization\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Define model\n","import torch.nn as nn\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","\n","        # Defined Layers\n","        self.fc1 = nn.Linear(28*28, 512)\n","        self.r1 = nn.ReLU()\n","\n","        self.fc2 = nn.Linear(512, 512)\n","        self.r2 = nn.ReLU()\n","\n","        self.fc3 = nn.Linear(512, 512)\n","        self.r3 = nn.ReLU()\n","\n","        self.fc4 = nn.Linear(512, 10)      # Output layer (10 classes)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","\n","        # Layer 1\n","        x = self.fc1(x)\n","        x = self.r1(x)\n","\n","        # Layer 2\n","        x = self.fc2(x)\n","        x = self.r2(x)\n","\n","        # Layer 3\n","        x = self.fc3(x)\n","        x = self.r3(x)\n","\n","        # Layer 4\n","        logits = self.fc4(x)\n","\n","        return logits\n","\n","# Initialize\n","\n","model = NeuralNetwork().to(device)\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"vIU3czYkzcnA"},"source":["# Optimizing the Model Parameters\n","To train a model, we need a loss function and an optimizer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQdICgCYyicQ"},"outputs":[],"source":["loss_fn = nn.CrossEntropyLoss()                             # CEL: loss Function for multi-class classification, BCE: Binary classifications\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)    # SGD : Optimizer, lr: Learning_rate"]},{"cell_type":"markdown","metadata":{"id":"bnXG2XB9zsQf"},"source":["In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model's parameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1j6Qr04Pzt5c"},"outputs":[],"source":["def train(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train()\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        # Compute prediction error\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()                             # Gradient must zero, reset every iteration\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), (batch + 1) * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"]},{"cell_type":"markdown","metadata":{"id":"BOsVQ2mxz0yg"},"source":["# We also check the model's performance against the test dataset to ensure it is learning."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4j1OxdNz506"},"outputs":[],"source":["def test(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"]},{"cell_type":"markdown","metadata":{"id":"lhUxqk2q0HBa"},"source":["The training process is conducted over several iterations (epochs).\n","\n","During each epoch, the model learns parameters to make better predictions.\n","\n","We print the model's accuracy and loss at each epoch; we'd like to see the accuracy increase and the loss decrease with every epoch."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77333,"status":"ok","timestamp":1770020595402,"user":{"displayName":"Hemant Pandey (G25AIT1065)","userId":"04373902719597689004"},"user_tz":-330},"id":"RVG_KXBY0LNb","outputId":"6479696e-d1ee-4f60-f40c-b659aef1e5cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","-------------------------------\n","loss: 2.301458  [   64/60000]\n","loss: 2.298745  [ 6464/60000]\n","loss: 2.295789  [12864/60000]\n","loss: 2.294936  [19264/60000]\n","loss: 2.283821  [25664/60000]\n","loss: 2.288132  [32064/60000]\n","loss: 2.284812  [38464/60000]\n","loss: 2.280998  [44864/60000]\n","loss: 2.278941  [51264/60000]\n","loss: 2.275712  [57664/60000]\n","Test Error: \n"," Accuracy: 35.7%, Avg loss: 2.272278 \n","\n","Epoch 2\n","-------------------------------\n","loss: 2.274998  [   64/60000]\n","loss: 2.273387  [ 6464/60000]\n","loss: 2.262054  [12864/60000]\n","loss: 2.266813  [19264/60000]\n","loss: 2.251383  [25664/60000]\n","loss: 2.243963  [32064/60000]\n","loss: 2.253301  [38464/60000]\n","loss: 2.238846  [44864/60000]\n","loss: 2.239194  [51264/60000]\n","loss: 2.226059  [57664/60000]\n","Test Error: \n"," Accuracy: 35.3%, Avg loss: 2.224423 \n","\n","Epoch 3\n","-------------------------------\n","loss: 2.231255  [   64/60000]\n","loss: 2.229787  [ 6464/60000]\n","loss: 2.203721  [12864/60000]\n","loss: 2.214800  [19264/60000]\n","loss: 2.189648  [25664/60000]\n","loss: 2.161458  [32064/60000]\n","loss: 2.186454  [38464/60000]\n","loss: 2.150969  [44864/60000]\n","loss: 2.152210  [51264/60000]\n","loss: 2.120000  [57664/60000]\n","Test Error: \n"," Accuracy: 36.4%, Avg loss: 2.121470 \n","\n","Epoch 4\n","-------------------------------\n","loss: 2.135430  [   64/60000]\n","loss: 2.130355  [ 6464/60000]\n","loss: 2.073574  [12864/60000]\n","loss: 2.094491  [19264/60000]\n","loss: 2.039971  [25664/60000]\n","loss: 1.982444  [32064/60000]\n","loss: 2.021327  [38464/60000]\n","loss: 1.946218  [44864/60000]\n","loss: 1.950346  [51264/60000]\n","loss: 1.880556  [57664/60000]\n","Test Error: \n"," Accuracy: 43.4%, Avg loss: 1.887876 \n","\n","Epoch 5\n","-------------------------------\n","loss: 1.919669  [   64/60000]\n","loss: 1.892401  [ 6464/60000]\n","loss: 1.785067  [12864/60000]\n","loss: 1.823545  [19264/60000]\n","loss: 1.711654  [25664/60000]\n","loss: 1.667815  [32064/60000]\n","loss: 1.694285  [38464/60000]\n","loss: 1.601806  [44864/60000]\n","loss: 1.627383  [51264/60000]\n","loss: 1.527130  [57664/60000]\n","Test Error: \n"," Accuracy: 50.8%, Avg loss: 1.547194 \n","\n","Done!\n"]}],"source":["epochs = 5                        #  One full pass over the dataset\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train(train_dataloader, model, loss_fn, optimizer)\n","    test(test_dataloader, model, loss_fn)\n","print(\"Done!\")"]},{"cell_type":"markdown","metadata":{"id":"pdtkFlbc0Qie"},"source":["# Saving Models\n","A common way to save a model is to serialize the internal state dictionary (containing the model parameters)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1770020595438,"user":{"displayName":"Hemant Pandey (G25AIT1065)","userId":"04373902719597689004"},"user_tz":-330},"id":"N1Co3xKL0c22","outputId":"8cd4dccc-61f5-434d-a448-1a84ffc08a4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saved PyTorch Model State to model.pth\n"]}],"source":["torch.save(model.state_dict(), \"model.pth\")           # Save weights\n","print(\"Saved PyTorch Model State to model.pth\")"]},{"cell_type":"markdown","metadata":{"id":"hRSYTiQeAtCx"},"source":["# Save Entire Model"]},{"cell_type":"markdown","metadata":{"id":"3NUPgvjs0jM_"},"source":["# Loading Models\n","The process for loading a model includes re-creating the model structure and loading the state dictionary into it."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1770020595472,"user":{"displayName":"Hemant Pandey (G25AIT1065)","userId":"04373902719597689004"},"user_tz":-330},"id":"228x2cCEA2lk","outputId":"a098f307-e062-47b9-aeaa-30577e714579"},"outputs":[{"output_type":"stream","name":"stdout","text":["Save Pytorch entire Model State to model.pth\n"]}],"source":["torch.save(model,'model.pth')                           # Saves architecture + weights\n","print(\"Save Pytorch entire Model State to model.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1770020595508,"user":{"displayName":"Hemant Pandey (G25AIT1065)","userId":"04373902719597689004"},"user_tz":-330},"id":"-vjZFmRO0olu","outputId":"f5778680-92a3-48f7-b99c-58b198b1e0af"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (fc1): Linear(in_features=784, out_features=512, bias=True)\n","  (r1): ReLU()\n","  (fc2): Linear(in_features=512, out_features=512, bias=True)\n","  (r2): ReLU()\n","  (fc3): Linear(in_features=512, out_features=512, bias=True)\n","  (r3): ReLU()\n","  (fc4): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":11}],"source":["model = torch.load(\"model.pth\", map_location=device, weights_only=False)      # Load entire model\n","model.eval()"]},{"cell_type":"markdown","metadata":{"id":"1PuUiZst0tr3"},"source":["This model can now be used to make predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1770020595550,"user":{"displayName":"Hemant Pandey (G25AIT1065)","userId":"04373902719597689004"},"user_tz":-330},"id":"G5BOjtId0zvz","outputId":"76ee1e5b-cd14-4af7-e16d-73815a8c3972"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"]}],"source":["classes = [\n","    \"T-shirt/top\",\n","    \"Trouser\",\n","    \"Pullover\",\n","    \"Dress\",\n","    \"Coat\",\n","    \"Sandal\",\n","    \"Shirt\",\n","    \"Sneaker\",\n","    \"Bag\",\n","    \"Ankle boot\",\n","]\n","\n","model.eval()\n","x, y = test_data[0][0], test_data[0][1]\n","with torch.no_grad():\n","    x = x.to(device)\n","    pred = model(x)\n","    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n","    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s15NpvD2I12T"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}